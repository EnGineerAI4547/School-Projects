# -*- coding: utf-8 -*-
"""Intro_Neural_Net_A2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GDHs5DSkyyKCMwzqYg5L7AWyGL3MA09X
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import tree



import numpy as np

from google.colab import files
uploaded = files.upload()

df= pd.read_csv('housing.header.binary.txt')
df

df.head()

features,labels=df.iloc[:,0:-1],df.loc[:,['Medv']]
features

labels

clf = tree.DecisionTreeClassifier(max_depth = 3)

clf.fit(features, labels)
tree.plot_tree(clf)

plt.rcParams.update({'font.size': 22})
fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (10,5), dpi=500)
tree.plot_tree(clf, feature_names = features.columns, class_names=['0','1'], filled = True);
fig.savefig('tree1.png')

X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=.2, random_state=42)



from sklearn.model_selection import KFold
X = np.array(X_train)
y = np.array(y_train)
kf = KFold(n_splits=3,shuffle=True)
# Returns the number of splitting iterations in the cross-validator
kf.get_n_splits(X)
for train_index, test_index in kf.split(X):
  print("TRAIN:", train_index, "TEST:", test_index)
  X_train, X_test = X[train_index], X[test_index]
  y_train, y_test = y[train_index], y[test_index]

clf.fit(X_train, y_train)
training=clf.predict(X_train)
tree.plot_tree(clf)
print(accuracy_score(y_train, training))

tree.plot_tree(clf)

y_pred=clf.predict(X_test)

tn,fp,fn,tp=confusion_matrix(y_test, y_pred).ravel()

from sklearn.metrics import classification_report, confusion_matrix,roc_auc_score
print(confusion_matrix(y_test, y_pred))
mat_con = (confusion_matrix(y_test, y_pred, labels=[1, 0]))

# Setting the attributes
fig, px = plt.subplots(figsize=(7.5, 7.5))
px.matshow(mat_con, cmap=plt.cm.YlOrRd, alpha=0.5)
for m in range(mat_con.shape[0]):
    for n in range(mat_con.shape[1]):
        px.text(x=n,y=m,s=mat_con[n, m], va='center', ha='center', size='xx-large')

# Sets the labels
plt.xlabel('Predictions', fontsize=16)
plt.ylabel('Actuals', fontsize=16)
plt.title('Confusion Matrix', fontsize=15)
plt.show()
print("\nThe classification report is=\n")
print(classification_report(y_test, y_pred))
print("The accuracy=%f"%accuracy_score(y_test, y_pred))
print("The true positive rate is %d"%tp)
print("The false positive rate is %d"%fp)
print("The true negative rate is %d"%tn)
print("The false negative rate is %d"%fn)
print("The false positive rate(NPR) is %f"%(fp/(fp+tn)))
print("The true positive rate(TPR) is %f"%(tp/(tp+fn)))

"""ROC and AUC vaue


"""

from sklearn.metrics import classification_report, confusion_matrix,roc_auc_score
prob=clf.predict_proba(X_test)
print(prob)

aucscore=roc_auc_score(y_test,prob[:,1])
print("\n\n\nAUC value is %f"% aucscore)

"""ROC graph

"""

fpr,tpr,thresholds=metrics.roc_curve(y_test,prob[:,1],pos_label=1)
print(fpr,tpr,thresholds)


plt.figure()
lw=2
plt.plot(fpr,tpr, color="darkorange",lw=lw,label="ROC curve (area =%0.4f)"%aucscore)
plt.plot([0,1],[0,1],color="navy",lw=lw, linestyle="--")
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Receiver Operator Characteristic")
plt.legend(loc="lower right")
plt.show()

plt.rcParams.update({'font.size': 22})
fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (10,5), dpi=500)
tree.plot_tree(clf, feature_names = X_train, class_names=['0','1'], filled = True);
fig.savefig('tree1.png')

from sklearn.metrics import confusion_matrix,accuracy_score
from sklearn.model_selection import KFold

features,labels=df.iloc[:,0:-1],df.loc[:,['Medv']]
X=features
y=labels
kf = KFold(n_splits=3,shuffle=True)
# Returns the number of splitting iterations in the cross-validator
kf.get_n_splits(X)

Acc1=[]
Acc2=[]
Acc3=[]
aucscore1=[]
aucscore2=[]
aucscore3=[]

for train_index, test_index in kf.split(X):
  X_train, X_test=X.iloc[train_index,:],X.iloc[test_index,:]
  y_train,y_test=y.iloc[train_index,:],y.iloc[test_index,:]
  clf1=tree.DecisionTreeClassifier(criterion="entropy", min_samples_split=1.0)
  clf1.fit(X_train,y_train)
  y_pred=clf1.predict(X_test)
  Acc1.append(accuracy_score(y_test, y_pred))
  clf2=tree.DecisionTreeClassifier(criterion="entropy", min_samples_split=3)
  clf2.fit(X_train, y_train)
  y_pred=clf2.predict(X_test)
  Acc2.append(accuracy_score(y_test, y_pred))

  clf3=tree.DecisionTreeClassifier(criterion="entropy", min_samples_split=5)
  clf3.fit(X_train, y_train)
  y_pred=clf3.predict(X_test)
  Acc3.append(accuracy_score(y_test, y_pred))

  prob=clf1.predict_proba(X_test)
  aucscore1.append(roc_auc_score(y_test,prob[:,1]))
  prob2=clf2.predict_proba(X_test)
  aucscore2.append(roc_auc_score(y_test,prob2[:,1]))
  prob3=clf3.predict_proba(X_test)
  aucscore3.append(roc_auc_score(y_test,prob3[:,1]))
  

 






print("The accuracies of the 1st classifier is %s"%Acc1)
print("AUC values of the 1st classifier is %s\n"% aucscore) 
print("The accuracies of the 2nd classifier is %s"%Acc2)
print("AUC values of the 2nd classifier is %s\n"% aucscore2)
print("The accuracies of the 3rd classifier is %s"%Acc3)
print("AUC values of the 3rd classifier is %s\n"% aucscore3)
print("The average accuracy of the `1st classifier is %.4f"% np.mean(Acc1))
print("The average accuracy of the `2nd classifier is %.4f"% np.mean(Acc2))
print("The average accuracy of the `3rd classifier is %.4f"% np.mean(Acc3))
print("The average AUC score of the `1st classifier is %.4f"% np.mean(aucscore1))
print("The average AUC score of the `2nd classifier is %.4f"% np.mean(aucscore2))
print("The average AUC score of the `3rd classifier is %.4f"% np.mean(aucscore3))